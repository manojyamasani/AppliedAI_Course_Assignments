{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5HExLQrE4ZxR"
   },
   "source": [
    "<h1><font color='blue'> 8E and 8F: Finding the Probability P(Y==1|X)</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4LuKrFzC4ZxV"
   },
   "source": [
    "<h2><font color='Geen'> 8E: Implementing Decision Function of SVM RBF Kernel</font></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1wES-wWN4ZxX"
   },
   "source": [
    "<font face=' Comic Sans MS' size=3>After we train a kernel SVM model, we will be getting support vectors and their corresponsing coefficients $\\alpha_{i}$\n",
    "\n",
    "Check the documentation for better understanding of these attributes: \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "<img src='https://i.imgur.com/K11msU4.png' width=500>\n",
    "\n",
    "As a part of this assignment you will be implementing the ```decision_function()``` of kernel SVM, here decision_function() means based on the value return by ```decision_function()``` model will classify the data point either as positive or negative\n",
    "\n",
    "Ex 1: In logistic regression After traning the models with the optimal weights $w$ we get, we will find the value $\\frac{1}{1+\\exp(-(wx+b))}$, if this value comes out to be < 0.5 we will mark it as negative class, else its positive class\n",
    "\n",
    "Ex 2: In Linear SVM After traning the models with the optimal weights $w$ we get, we will find the value of $sign(wx+b)$, if this value comes out to be -ve we will mark it as negative class, else its positive class.\n",
    "\n",
    "Similarly in Kernel SVM After traning the models with the coefficients $\\alpha_{i}$ we get, we will find the value of \n",
    "$sign(\\sum_{i=1}^{n}(y_{i}\\alpha_{i}K(x_{i},x_{q})) + intercept)$, here $K(x_{i},x_{q})$ is the RBF kernel. If this value comes out to be -ve we will mark $x_{q}$ as negative class, else its positive class.\n",
    "\n",
    "RBF kernel is defined as: $K(x_{i},x_{q})$ = $exp(-\\gamma ||x_{i} - x_{q}||^2)$\n",
    "\n",
    "For better understanding check this link: https://scikit-learn.org/stable/modules/svm.html#svm-mathematical-formulation\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z830CfMk4Zxa"
   },
   "source": [
    "## Task E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MuBxHiCQ4Zxc"
   },
   "source": [
    "> 1. Split the data into $X_{train}$(60), $X_{cv}$(20), $X_{test}$(20)\n",
    "\n",
    "> 2. Train $SVC(gamma=0.001, C=100.)$ on the ($X_{train}$, $y_{train}$)\n",
    "\n",
    "> 3. Get the decision boundry values $f_{cv}$ on the $X_{cv}$ data  i.e. ` `$f_{cv}$ ```= decision_function(```$X_{cv}$```)```  <font color='red'>you need to implement this decision_function()</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1817,
     "status": "ok",
     "timestamp": 1597519118722,
     "user": {
      "displayName": "MANOJKUMAR YAMASANI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi_mSk1lRQHvKsofeowdqYTJCL4SZRPDcyq0n0Wlg=s64",
      "userId": "15946760704204620758"
     },
     "user_tz": -330
    },
    "id": "fCgMNEvI4Zxf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1805,
     "status": "ok",
     "timestamp": 1597519118724,
     "user": {
      "displayName": "MANOJKUMAR YAMASANI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi_mSk1lRQHvKsofeowdqYTJCL4SZRPDcyq0n0Wlg=s64",
      "userId": "15946760704204620758"
     },
     "user_tz": -330
    },
    "id": "ANUNIqCe4Zxn",
    "outputId": "023dfda9-1e95-4f6a-9c7c-c0af0211350b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 5)"
      ]
     },
     "execution_count": 83,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=5000, n_features=5, n_redundant=2,\n",
    "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tHie1zqH4Zxt"
   },
   "source": [
    "### Pseudo code\n",
    "\n",
    "clf = SVC(gamma=0.001, C=100.)<br>\n",
    "clf.fit(Xtrain, ytrain)\n",
    "\n",
    "<font color='green'>def</font> <font color='blue'>decision_function</font>(Xcv, ...): #use appropriate parameters <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color='green'>for</font> a data point $x_q$ <font color='green'>in</font> Xcv: <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color='grey'>#write code to implement $(\\sum_{i=1}^{\\text{all the support vectors}}(y_{i}\\alpha_{i}K(x_{i},x_{q})) + intercept)$, here the values $y_i$, $\\alpha_{i}$, and $intercept$ can be obtained from the trained model</font><br>\n",
    "   <font color='green'>return</font> <font color='grey'><i># the decision_function output for all the data points in the Xcv</i></font>\n",
    "    \n",
    "fcv = decision_function(Xcv, ...)  <i># based on your requirement you can pass any other parameters </i>\n",
    "\n",
    "<b>Note</b>: Make sure the values you get as fcv, should be equal to outputs of clf.decision_function(Xcv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1795,
     "status": "ok",
     "timestamp": 1597519118725,
     "user": {
      "displayName": "MANOJKUMAR YAMASANI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi_mSk1lRQHvKsofeowdqYTJCL4SZRPDcyq0n0Wlg=s64",
      "userId": "15946760704204620758"
     },
     "user_tz": -330
    },
    "id": "h43kDT3M41u5"
   },
   "outputs": [],
   "source": [
    "# you can write your code here\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "X_tr,X_cv,Y_tr,Y_cv = train_test_split(X_train,Y_train,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1786,
     "status": "ok",
     "timestamp": 1597519118726,
     "user": {
      "displayName": "MANOJKUMAR YAMASANI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi_mSk1lRQHvKsofeowdqYTJCL4SZRPDcyq0n0Wlg=s64",
      "userId": "15946760704204620758"
     },
     "user_tz": -330
    },
    "id": "hEbRXDN7jE3u"
   },
   "outputs": [],
   "source": [
    "def decision_function(Xcv,sv,y_alp,intercept,gam):\n",
    "  dec_fn = []\n",
    "  #print(sv)\n",
    "  #print(gam)\n",
    "  #print(len(Xcv))\n",
    "  for i in range(len(Xcv)):\n",
    "    sum = 0\n",
    "    for j in range(len(sv)):\n",
    "      sum +=  (y_alp[j]*np.exp(-1*np.sum((Xcv[i,:]-sv[j,:])**2)*gam))\n",
    "    dec_fn.append((sum+intercept).tolist())\n",
    "  \n",
    "  dec_fn = [i[0] for i in dec_fn]\n",
    "  return dec_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7769,
     "status": "ok",
     "timestamp": 1597519124724,
     "user": {
      "displayName": "MANOJKUMAR YAMASANI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi_mSk1lRQHvKsofeowdqYTJCL4SZRPDcyq0n0Wlg=s64",
      "userId": "15946760704204620758"
     },
     "user_tz": -330
    },
    "id": "eCOPK03aisoQ",
    "outputId": "d814e13c-f9ac-498c-9318-2c38f5f7fe58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "561\n"
     ]
    }
   ],
   "source": [
    "gam = 0.001\n",
    "clf = SVC(gamma= gam, C=100)\n",
    "clf.fit(X_tr, Y_tr)\n",
    "print(len(clf.support_))\n",
    "y_alpha = clf.dual_coef_\n",
    "intercept = clf.intercept_\n",
    "sv = clf.support_vectors_\n",
    "#print((y_alpha))\n",
    "dec_fn_implem = decision_function(X_cv,sv,y_alpha[0],intercept,gam)\n",
    "dec_fn_inbuilt = clf.decision_function(X_cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7760,
     "status": "ok",
     "timestamp": 1597519124732,
     "user": {
      "displayName": "MANOJKUMAR YAMASANI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi_mSk1lRQHvKsofeowdqYTJCL4SZRPDcyq0n0Wlg=s64",
      "userId": "15946760704204620758"
     },
     "user_tz": -330
    },
    "id": "PbYi3vUSsl2d",
    "outputId": "20c9d687-ca5c-49b4-8250-c21f5bfa7666"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function based decision function values are [-4.161095825122163, 1.7233399647584635, -2.6499005585185555, 1.3091961267094492, -0.3664902922009814]\n",
      "sklearn based decision function values are  [-4.161095825122163, 1.7233399647584635, -2.6499005585185555, 1.3091961267094492, -0.3664902922009814]\n"
     ]
    }
   ],
   "source": [
    "print(\"Function based decision function values are\",dec_fn_implem[:5])\n",
    "print(\"sklearn based decision function values are \",dec_fn_inbuilt.tolist()[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b6aZwVe-5D2W"
   },
   "source": [
    "we can observe that both implementations result in the same values of decision function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A01UElCkzA5W"
   },
   "source": [
    "From above we can observe that the function implementation result and inbuilt scikitlearn function results are same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c0bKCboN4Zxu"
   },
   "source": [
    "<h2><font color='Geen'> 8F: Implementing Platt Scaling to find P(Y==1|X)</font></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nMn7OEN94Zxw"
   },
   "source": [
    "Check this <a href='https://drive.google.com/open?id=133odBinMOIVb_rh_GQxxsyMRyW-Zts7a'>PDF</a>\n",
    "<img src='https://i.imgur.com/CAMnVnh.png'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e0n5EFkx4Zxz"
   },
   "source": [
    "## TASK F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t0HOqVJq4Zx1"
   },
   "source": [
    "\n",
    "> 4. Apply SGD algorithm with ($f_{cv}$, $y_{cv}$) and find the weight $W$ intercept $b$ ```Note: here our data is of one dimensional so we will have a one dimensional weight vector i.e W.shape (1,)``` \n",
    "\n",
    "> Note1: Don't forget to change the values of $y_{cv}$ as mentioned in the above image. you will calculate y+, y- based on data points in train data\n",
    "\n",
    "> Note2: the Sklearn's SGD algorithm doesn't support the real valued outputs, you need to use the code that was done in the `'Logistic Regression with SGD and L2'` Assignment after modifying loss function, and use same parameters that used in that assignment.\n",
    "<img src='https://i.imgur.com/zKYE9Oc.png'>\n",
    "if Y[i] is 1, it will be replaced with y+ value else it will replaced with y- value\n",
    "\n",
    "> 5. For a given data point from $X_{test}$, $P(Y=1|X) = \\frac{1}{1+exp(-(W*f_{test}+ b))}$ where ` `$f_{test}$ ```= decision_function(```$X_{test}$```)```, W and b will be learned as metioned in the above step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7749,
     "status": "ok",
     "timestamp": 1597519124734,
     "user": {
      "displayName": "MANOJKUMAR YAMASANI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi_mSk1lRQHvKsofeowdqYTJCL4SZRPDcyq0n0Wlg=s64",
      "userId": "15946760704204620758"
     },
     "user_tz": -330
    },
    "id": "hJpwlTvcIdDc"
   },
   "outputs": [],
   "source": [
    "def logloss(y_true,y_pred):\n",
    "    '''In this function, we will compute log loss '''\n",
    "\n",
    "    n = len(y_true)\n",
    "    x = np.log10(y_pred)\n",
    "    x1 =  np.log10(np.ones_like(y_pred) - y_pred)\n",
    "    loss = 0\n",
    "    for j in range(n):\n",
    "      loss = loss +((y_true[j]*x[j])+((1-y_true[j])*x1[j]))\n",
    "    loss*=(-1/n)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7741,
     "status": "ok",
     "timestamp": 1597519124736,
     "user": {
      "displayName": "MANOJKUMAR YAMASANI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi_mSk1lRQHvKsofeowdqYTJCL4SZRPDcyq0n0Wlg=s64",
      "userId": "15946760704204620758"
     },
     "user_tz": -330
    },
    "id": "GecwYV9fsKZ9"
   },
   "outputs": [],
   "source": [
    "def initialize_weights(dim):\n",
    "    ''' In this function, we will initialize our weights and bias'''\n",
    "    #initialize the weights to zeros array of (1,dim) dimensions\n",
    "    #you use zeros_like function to initialize zero, check this link https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros_like.html\n",
    "    #initialize bias to zero\n",
    "\n",
    "    w = np.zeros_like(dim)\n",
    "    b = 0\n",
    "\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7732,
     "status": "ok",
     "timestamp": 1597519124737,
     "user": {
      "displayName": "MANOJKUMAR YAMASANI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi_mSk1lRQHvKsofeowdqYTJCL4SZRPDcyq0n0Wlg=s64",
      "userId": "15946760704204620758"
     },
     "user_tz": -330
    },
    "id": "nAfmQF47_Sd6"
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    ''' In this function, we will return sigmoid of z'''\n",
    "    # compute sigmoid(z) and return\n",
    "\n",
    "    sigma = (1/(1+np.exp(-z)))\n",
    "\n",
    "    return sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7724,
     "status": "ok",
     "timestamp": 1597519124738,
     "user": {
      "displayName": "MANOJKUMAR YAMASANI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi_mSk1lRQHvKsofeowdqYTJCL4SZRPDcyq0n0Wlg=s64",
      "userId": "15946760704204620758"
     },
     "user_tz": -330
    },
    "id": "NMVikyuFsKo5"
   },
   "outputs": [],
   "source": [
    "def gradient_dw(x,y,w,b,alpha,N):\n",
    "    '''In this function, we will compute the gardient w.r.to w '''\n",
    "\n",
    "    dw = (x*(y - sigmoid(np.matmul(w,x) + b))) - ((alpha/N)*w)\n",
    "\n",
    "    return dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7716,
     "status": "ok",
     "timestamp": 1597519124739,
     "user": {
      "displayName": "MANOJKUMAR YAMASANI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi_mSk1lRQHvKsofeowdqYTJCL4SZRPDcyq0n0Wlg=s64",
      "userId": "15946760704204620758"
     },
     "user_tz": -330
    },
    "id": "0nUf2ft4EZp8"
   },
   "outputs": [],
   "source": [
    " def gradient_db(x,y,w,b):\n",
    "     '''In this function, we will compute gradient w.r.to b '''\n",
    "\n",
    "     db = (y - sigmoid(np.matmul(w,x) + b))\n",
    "\n",
    "     return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7707,
     "status": "ok",
     "timestamp": 1597519124740,
     "user": {
      "displayName": "MANOJKUMAR YAMASANI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi_mSk1lRQHvKsofeowdqYTJCL4SZRPDcyq0n0Wlg=s64",
      "userId": "15946760704204620758"
     },
     "user_tz": -330
    },
    "id": "dmAdc5ejEZ25"
   },
   "outputs": [],
   "source": [
    "def train(X_train,y_train,epochs,alpha,eta0):\n",
    "    ''' In this function, we will implement logistic regression'''\n",
    "    #Here eta0 is learning rate\n",
    "    #implement the code as follows\n",
    "    # initalize the weights (call the initialize_weights(X_train[0]) function)\n",
    "    # for every epoch\n",
    "        # for every data point(X_train,y_train)\n",
    "           #compute gradient w.r.to w (call the gradient_dw() function)\n",
    "           #compute gradient w.r.to b (call the gradient_db() function)\n",
    "           #update w, b\n",
    "        # predict the output of x_train[for all data points in X_train] using w,b\n",
    "        #compute the loss between predicted and actual values (call the loss function)\n",
    "        # store all the train loss values in a list\n",
    "        # predict the output of x_test[for all data points in X_test] using w,b\n",
    "        #compute the loss between predicted and actual values (call the loss function)\n",
    "        # store all the test loss values in a list\n",
    "        # you can also compare previous loss and current loss, if loss is not updating then stop the process and return w,b\n",
    "\n",
    "    w,b = initialize_weights(X_train[0])\n",
    "    N = len(X_train)\n",
    "    \n",
    "    loss_train = []\n",
    "    for i in range(epochs):\n",
    "      w_prev,b_prev = w,b\n",
    "      y_pred_train = []\n",
    "      for j in range(len(X_train)):\n",
    "        dw = gradient_dw(X_train[j,:], y_train[j], w, b, alpha, N)\n",
    "        db = gradient_db(X_train[j,:], y_train[j], w, b)\n",
    "\n",
    "        w = w + (eta0 * dw)\n",
    "        b = b + (eta0 * db)\n",
    "      for j in range(len(X_train)):\n",
    "        y_pred_train.append(sigmoid(np.matmul(w,X_train[j,:]) + b))\n",
    "      \n",
    "      present=logloss(y_train, y_pred_train)\n",
    "      loss_train.append(present)\n",
    "      #print(present)\n",
    "\n",
    "      if(i!=0 and loss_train[i-1]<present):\n",
    "        print(\"Minimum loss achieved is\",loss_train[i-1])\n",
    "        return w_prev,b_prev,loss_train[:i]\n",
    "    print(\"Minimum loss achieved is\",present)\n",
    "    return w,b,loss_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7696,
     "status": "ok",
     "timestamp": 1597519124741,
     "user": {
      "displayName": "MANOJKUMAR YAMASANI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi_mSk1lRQHvKsofeowdqYTJCL4SZRPDcyq0n0Wlg=s64",
      "userId": "15946760704204620758"
     },
     "user_tz": -330
    },
    "id": "9N1eOAR3CfMA",
    "outputId": "90552bc3-5c65-48b2-ffeb-6756c87d5c18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 1]\n",
      "[0.00048192771084337347, 0.9989235737351991, 0.00048192771084337347, 0.9989235737351991]\n"
     ]
    }
   ],
   "source": [
    "N_pos = np.count_nonzero(Y_tr)\n",
    "N_neg = len(Y_tr)-N_pos\n",
    "y_pos = (N_pos+1)/(N_pos+2)\n",
    "y_neg = (1/(N_neg+2))\n",
    "#print(N_pos,N_neg,y_pos,y_neg)\n",
    "print(Y_cv.tolist()[:4])\n",
    "Y_cv_mod = np.zeros_like(Y_cv,dtype =float)\n",
    "for i in range(len(Y_cv)):\n",
    "  if Y_cv[i]==1:\n",
    "    Y_cv_mod[i] = y_pos \n",
    "  else:\n",
    "    Y_cv_mod[i] = y_neg\n",
    "print(Y_cv_mod.tolist()[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2P8iQByD5l_c"
   },
   "source": [
    "In the above results, list-1 indicates true or actual labels of Y_cv.\n",
    "list-2 indicates the modified labels of Y_cv according to the given formulae.\n",
    "\n",
    "We can observe that 0 label is replaced with 0.0004766 and label 1 is replaced with 0.9988962 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24817,
     "status": "ok",
     "timestamp": 1597519141875,
     "user": {
      "displayName": "MANOJKUMAR YAMASANI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi_mSk1lRQHvKsofeowdqYTJCL4SZRPDcyq0n0Wlg=s64",
      "userId": "15946760704204620758"
     },
     "user_tz": -330
    },
    "id": "b3Hp05lAKGVH",
    "outputId": "3bc76ab0-f765-4045-efa7-2b5e649ba27e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum loss achieved is [0.07559336]\n"
     ]
    }
   ],
   "source": [
    "alpha=0.0001\n",
    "eta0=0.001\n",
    "N=len(X_tr)\n",
    "epochs=1000\n",
    "#print(np.array(dec_fn_implem).reshape(-1,1),np.array(Y_cv_mod).reshape(-1,1))\n",
    "f_cv = np.array(dec_fn_implem).reshape(-1,1)\n",
    "Y_cv_mod = np.array(Y_cv_mod).reshape(-1,1)\n",
    "w,b,train_loss = train(f_cv,Y_cv_mod,epochs,alpha,eta0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24803,
     "status": "ok",
     "timestamp": 1597519141876,
     "user": {
      "displayName": "MANOJKUMAR YAMASANI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi_mSk1lRQHvKsofeowdqYTJCL4SZRPDcyq0n0Wlg=s64",
      "userId": "15946760704204620758"
     },
     "user_tz": -330
    },
    "id": "pofZH9XMKv1Z",
    "outputId": "25ce7405-dacf-445c-e4de-b999e66e956c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs=[i for i in range(len(train_loss))]\n",
    "plt.plot(epochs,train_loss,label= 'Train Loss')\n",
    "\n",
    "plt.scatter(epochs,train_loss)\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Epochs vs Logistic Loss graph')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Logistic loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29581,
     "status": "ok",
     "timestamp": 1597519146665,
     "user": {
      "displayName": "MANOJKUMAR YAMASANI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi_mSk1lRQHvKsofeowdqYTJCL4SZRPDcyq0n0Wlg=s64",
      "userId": "15946760704204620758"
     },
     "user_tz": -330
    },
    "id": "4VdPvlyqPJz7",
    "outputId": "06ed7a50-d14d-4b03-847d-5bbbe2856762"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.392145229826883, -2.9514350778685126, -1.6627732024593085, -4.619833147669826]\n",
      "[0.011427693208354434, 0.003914680589311406, 0.04507717531280103, 0.00015725892037058434]\n"
     ]
    }
   ],
   "source": [
    "f_test = decision_function(X_test,sv,y_alpha[0],intercept,gam)\n",
    "print(f_test[:4])\n",
    "proba_1=[]\n",
    "for i in range(len(X_test)):  \n",
    "  proba_1.append(sigmoid(np.dot(w,f_test[i]) + b))\n",
    "\n",
    "proba_1 = [i.tolist() for i in proba_1] \n",
    "proba_1 = [i[0] for i in proba_1]\n",
    "print(proba_1[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i9cqChyrViB9"
   },
   "source": [
    "we can observe that if decision function value is negative it's probability of being class 1 $P(y=1/x)< 0.5 $ and is low and if it is positive it's $P(y=1/x) > 0.5$ and high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oTY7z2bd4Zx2"
   },
   "source": [
    "__Note: in the above algorithm, the steps 2, 4 might need hyper parameter tuning, To reduce the complexity of the assignment we are excluding the hyerparameter tuning part, but intrested students can try that__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CM3odN1Z4Zx3"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "If any one wants to try other calibration algorithm istonic regression also please check these tutorials\n",
    "\n",
    "1. http://fa.bianp.net/blog/tag/scikit-learn.html#fn:1\n",
    "\n",
    "2. https://drive.google.com/open?id=1MzmA7QaP58RDzocB0RBmRiWfl7Co_VJ7\n",
    "\n",
    "3. https://drive.google.com/open?id=133odBinMOIVb_rh_GQxxsyMRyW-Zts7a\n",
    "\n",
    "4. https://stat.fandom.com/wiki/Isotonic_regression#Pool_Adjacent_Violators_Algorithm\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "8E_F_LR_SVM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}